{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "========================================================================================================================================================================================================\n",
       "Layer (type (var_name):depth-idx)                                           Input Shape               Output Shape              Param #                   Mult-Adds                 Trainable\n",
       "========================================================================================================================================================================================================\n",
       "DistilBertForSequenceClassification (DistilBertForSequenceClassification)   [8, 128]                  [8, 7]                    --                        --                        True\n",
       "├─DistilBertModel (distilbert): 1-1                                         --                        [8, 128, 768]             --                        --                        True\n",
       "│    └─Embeddings (embeddings): 2-1                                         [8, 128]                  [8, 128, 768]             --                        --                        True\n",
       "│    │    └─Embedding (word_embeddings): 3-1                                [8, 128]                  [8, 128, 768]             23,440,896                187,527,168               True\n",
       "│    │    └─Embedding (position_embeddings): 3-2                            [1, 128]                  [1, 128, 768]             393,216                   393,216                   True\n",
       "│    │    └─LayerNorm (LayerNorm): 3-3                                      [8, 128, 768]             [8, 128, 768]             1,536                     12,288                    True\n",
       "│    │    └─Dropout (dropout): 3-4                                          [8, 128, 768]             [8, 128, 768]             --                        --                        --\n",
       "│    └─Transformer (transformer): 2-2                                       --                        [8, 128, 768]             --                        --                        True\n",
       "│    │    └─ModuleList (layer): 3-5                                         --                        --                        42,527,232                --                        True\n",
       "├─Linear (pre_classifier): 1-2                                              [8, 768]                  [8, 768]                  590,592                   4,724,736                 True\n",
       "├─Dropout (dropout): 1-3                                                    [8, 768]                  [8, 768]                  --                        --                        --\n",
       "├─Linear (classifier): 1-4                                                  [8, 768]                  [8, 7]                    5,383                     43,064                    True\n",
       "========================================================================================================================================================================================================\n",
       "Total params: 66,958,855\n",
       "Trainable params: 66,958,855\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 532.92\n",
       "========================================================================================================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 428.66\n",
       "Params size (MB): 267.84\n",
       "Estimated Total Size (MB): 696.50\n",
       "========================================================================================================================================================================================================"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "checkpoint = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=7, ignore_mismatched_sizes=True)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=torch.randint(1, 30000, (8, 128)),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\", \"trainable\"],\n",
    "    row_settings=[\"depth\", \"var_names\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to freeze the whole model except for classifier, and see if this will be enough for training. Model summary helped me to find out last layer name (classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================================================================================================\n",
       "Layer (type (var_name):depth-idx)                                           Input Shape               Output Shape              Param #                   Mult-Adds                 Trainable\n",
       "========================================================================================================================================================================================================\n",
       "DistilBertForSequenceClassification (DistilBertForSequenceClassification)   [8, 128]                  [8, 7]                    --                        --                        Partial\n",
       "├─DistilBertModel (distilbert): 1-1                                         --                        [8, 128, 768]             --                        --                        False\n",
       "│    └─Embeddings (embeddings): 2-1                                         [8, 128]                  [8, 128, 768]             --                        --                        False\n",
       "│    │    └─Embedding (word_embeddings): 3-1                                [8, 128]                  [8, 128, 768]             (23,440,896)              187,527,168               False\n",
       "│    │    └─Embedding (position_embeddings): 3-2                            [1, 128]                  [1, 128, 768]             (393,216)                 393,216                   False\n",
       "│    │    └─LayerNorm (LayerNorm): 3-3                                      [8, 128, 768]             [8, 128, 768]             (1,536)                   12,288                    False\n",
       "│    │    └─Dropout (dropout): 3-4                                          [8, 128, 768]             [8, 128, 768]             --                        --                        --\n",
       "│    └─Transformer (transformer): 2-2                                       --                        [8, 128, 768]             --                        --                        False\n",
       "│    │    └─ModuleList (layer): 3-5                                         --                        --                        (42,527,232)              --                        False\n",
       "├─Linear (pre_classifier): 1-2                                              [8, 768]                  [8, 768]                  (590,592)                 4,724,736                 False\n",
       "├─Dropout (dropout): 1-3                                                    [8, 768]                  [8, 768]                  --                        --                        --\n",
       "├─Linear (classifier): 1-4                                                  [8, 768]                  [8, 7]                    5,383                     43,064                    True\n",
       "========================================================================================================================================================================================================\n",
       "Total params: 66,958,855\n",
       "Trainable params: 5,383\n",
       "Non-trainable params: 66,953,472\n",
       "Total mult-adds (Units.MEGABYTES): 532.92\n",
       "========================================================================================================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 428.66\n",
       "Params size (MB): 267.84\n",
       "Estimated Total Size (MB): 696.50\n",
       "========================================================================================================================================================================================================"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.requires_grad_(False)\n",
    "model.classifier.requires_grad_(True)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=torch.randint(1, 30000, (8, 128)),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\", \"trainable\"],\n",
    "    row_settings=[\"depth\", \"var_names\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus total number of trainable parameters will be 5,383."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
